# Back to Bruce: The Nine Cardinal Parameters
Filled in with [Chandra's values](https://ncbi.ncm.nih.gov/pmc/articles/PMC3550641/) in Table 2:

AMBIENT:
1. TEMP     - 30C
2. HUMIDITY - 60%
3. WIND     - ?
4. CO2      - 750 PPM

SOIL:
1. ROOT-ZONE TEMP - ?
2. NUTRIENTS      - ?
3. OXYGEN         - ?
4. WATER          - ?

PPFD drives plant growth. The relation between PPFD and nutrient exhaustion is not yet quantified, but can be inferred by electroconductivity of runoff(measured in PPM). An unrelated, but also import question is: What soil composition is optimized for yield?  The most significant emendation of Bruce's work which lies to us to perform is:

1. Quantifying nutrient consumption rate as a relation between:
   1. initial concentration of nutrients in soil
   2. amount of water in a day
   3. DLI
Which is the relation between PPFD|DLI, and run-off measured in electroconductive PartsPerMillion. The run-off is composed electroconductive nutrients "washed" out of the root-zone. These are already used by the plant.


# Measurement devices
1. PPFD
2. VPD
3. SOIL PPM (electroconductivity)


It is of primary importance that we are able to measure ambient CO2. From the paper of [Chandra et al.](https://ncbi.ncm.nih.gov/pmc/articles/PMC3550641/), PPFD oughtta be ~1500 umol/m^2*s, and CO2 concentration should be, optimally, around 750 umol/mol, where the latter mol is of quantity of air. Chandra's finding is easily translated into PPM.

# Our plan -- learn statistics to draw inferential power from a 'gross' collection of data
In Chandra et al's' paper, I was struck by the use of statistical methods to determine which quantities had a correlation. Now, we can expect to draw meaningful conclusions from whatever data we gather. We want _quantized causes_ -- will statistical inference yield them? My current understanding is that the null hypothesis is a function(?), whose arguments return the degree of "confidence" (whose meaning is what?) that the proposition is truth-valued. What, exactly, was Chandra enabled to do via statistical modes of inference? How do I use this power for my experiments? The identities he correlates all belong to the SI. 

# Kant and Popper
The condition of validity of a body of science: that it obey the principle of non-contradiction. The condition of applicability of a body of science: that the self-consistent, valid inferences it engenders do not contradict experience, and in fact, predict any possible experience.

# Geometry
The intelligibility of Lobachevskian geometry suffices to prove this. Geometrical science proceeds by analyzing the bearing of constructions on a problem, or theorem. A schema relates the constructed appearance (e.g. diagram) to a subsuming concept, which the construction objectifies. Hence my proof holds good for all triangles, in spite of my poor drawing.

# Physics
Physics is experimental philosophy. It can only proceed by perpetual confirmation. The only meaning of the mathematical identities treated in physics is experimental. It attributes, to all effects, quantized causes. The deterministic worldview cannot be translated to the microscopic, quantum physical level. Here statistical methods must be used to express the "tendency" of a system. Stats seem to be an emendation of analysis and synthesis, as applied to appearances, which are schematized independently of a taxonomical order of classes. This is to say that statistical inference does not classify all of the objects it deals with by, from my naive point of view, any taxa.
